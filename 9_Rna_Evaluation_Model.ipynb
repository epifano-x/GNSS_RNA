{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# 9_Rna_Evaluation_Simplified.ipynb\n",
       "\n",
       "## Visão Geral\n",
       "\n",
       "Este notebook carrega o modelo previamente treinado (`final_residual_model.h5`) e avalia seu desempenho em um dataset de teste (origem: arquivo JSON). Em seguida, gera gráficos para análise dos erros. Nesta versão, foram adicionados gráficos que focam nos valores centrais (já que a maioria dos erros está próxima de zero) e uma estratificação dos resultados por faixa de latitude, a fim de visualizar melhor a distribuição dos erros e identificar outliers.\n",
       "\n",
       "> **Observação**: Se a normalização utilizada no treino for diferente, o ideal é salvar o objeto `scaler` e reaplicá-lo; aqui refitamos com `StandardScaler` para simplificar."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import os\n",
       "import ijson\n",
       "import numpy as np\n",
       "import pandas as pd\n",
       "import matplotlib.pyplot as plt\n",
       "import seaborn as sns\n",
       "\n",
       "import tensorflow as tf\n",
       "from tensorflow.keras.models import load_model\n",
       "\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.preprocessing import StandardScaler\n",
       "\n",
       "# Configurações iniciais\n",
       "sns.set_theme(style=\"whitegrid\")\n",
       "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
       "\n",
       "# Caminhos\n",
       "JSON_PATH = \"Dataset_Vetor.json\"     # Altere conforme seu JSON de teste\n",
       "MODEL_PATH = \"final_residual_model.h5\" # Modelo salvo do treino\n",
       "\n",
       "# Colunas target\n",
       "TARGET_COLS = [\"diferencalatitudeMetros\", \"diferencalongitudeMetros\"]\n",
       "\n",
       "# Limite de amostras (None para usar todas)\n",
       "MAX_SAMPLES = None\n",
       "\n",
       "if not tf.config.list_physical_devices('GPU'):\n",
       "    print(\"[AVISO] Nenhuma GPU detectada. Usando CPU.\")\n",
       "else:\n",
       "    print(f\"[INFO] GPU detectada: {[gpu.name for gpu in tf.config.list_physical_devices('GPU')]}\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def discover_feature_keys(json_path, max_samples=None):\n",
       "    feature_keys_set = set()\n",
       "    with open(json_path, \"rb\") as f:\n",
       "        parser = ijson.items(f, \"item\")\n",
       "        count = 0\n",
       "        for record in parser:\n",
       "            for k in record.keys():\n",
       "                if k not in TARGET_COLS:\n",
       "                    feature_keys_set.add(k)\n",
       "            count += 1\n",
       "            if max_samples and count >= max_samples:\n",
       "                break\n",
       "    return sorted(feature_keys_set)\n",
       "\n",
       "def dict_to_numpy_fixed(record, feature_keys):\n",
       "    # Verifica se todas as targets existem\n",
       "    for col in TARGET_COLS:\n",
       "        if col not in record:\n",
       "            return None, None\n",
       "    try:\n",
       "        lat = float(record[\"diferencalatitudeMetros\"])\n",
       "        lon = float(record[\"diferencalongitudeMetros\"])\n",
       "    except:\n",
       "        return None, None\n",
       "    y_array = np.array([lat, lon], dtype=np.float32)\n",
       "    X_array = np.zeros(len(feature_keys), dtype=np.float32)\n",
       "    for i, k in enumerate(feature_keys):\n",
       "        try:\n",
       "            X_array[i] = float(record.get(k, 0.0))\n",
       "        except:\n",
       "            X_array[i] = 0.0\n",
       "    return X_array, y_array\n",
       "\n",
       "def read_dataset(json_path, feature_keys, max_samples=None):\n",
       "    dataX, dataY = [], []\n",
       "    count = 0\n",
       "    with open(json_path, \"rb\") as f:\n",
       "        parser = ijson.items(f, \"item\")\n",
       "        for record in parser:\n",
       "            X, y = dict_to_numpy_fixed(record, feature_keys)\n",
       "            if X is not None and y is not None:\n",
       "                dataX.append(X)\n",
       "                dataY.append(y)\n",
       "            count += 1\n",
       "            if max_samples and count >= max_samples:\n",
       "                break\n",
       "    return np.array(dataX, dtype=np.float32), np.array(dataY, dtype=np.float32)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 1) Descobrir features e carregar dados\n",
       "print(\"[INFO] Descobrindo features...\")\n",
       "feature_keys = discover_feature_keys(JSON_PATH, max_samples=MAX_SAMPLES)\n",
       "if not feature_keys:\n",
       "    raise ValueError(\"Não encontrou features. Verifique seu JSON.\")\n",
       "\n",
       "print(\"[INFO] Lendo dados...\")\n",
       "X_all, y_all = read_dataset(JSON_PATH, feature_keys, max_samples=MAX_SAMPLES)\n",
       "print(f\"Formato do dataset X: {X_all.shape}\")\n",
       "print(f\"Formato do dataset y: {y_all.shape}\")\n",
       "\n",
       "print(f\"[INFO] Carregando modelo {MODEL_PATH}...\")\n",
       "model = load_model(MODEL_PATH)\n",
       "print(\"Modelo carregado com sucesso!\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 2) Split e normalização\n",
       "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.45, random_state=42)\n",
       "\n",
       "scaler = StandardScaler()\n",
       "scaler.fit(X_train)\n",
       "\n",
       "X_train_scaled = scaler.transform(X_train)\n",
       "X_test_scaled = scaler.transform(X_test)\n",
       "\n",
       "print(f\"[INFO] X_test shape: {X_test_scaled.shape}\")\n",
       "print(f\"[INFO] y_test shape: {y_test.shape}\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 3) Avaliação do modelo\n",
       "print(\"[INFO] Avaliando o modelo no conjunto de TEST...\")\n",
       "results = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
       "print(f\"Loss (MSE)={results[0]:.4f}, MAE={results[1]:.4f}, MSE={results[2]:.4f}\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 4) Predições e criação do DataFrame\n",
       "print(\"Calculando predições...\")\n",
       "y_pred = model.predict(X_test_scaled, batch_size=8192, verbose=0)\n",
       "print(f\"Predições obtidas: {y_pred.shape}\")\n",
       "\n",
       "# Criar DataFrame\n",
       "df_test = pd.DataFrame({\n",
       "    'real_lat': y_test[:, 0],\n",
       "    'real_lon': y_test[:, 1],\n",
       "    'pred_lat': y_pred[:, 0],\n",
       "    'pred_lon': y_pred[:, 1]\n",
       "})\n",
       "\n",
       "df_test['err_lat'] = df_test['pred_lat'] - df_test['real_lat']\n",
       "df_test['err_lon'] = df_test['pred_lon'] - df_test['real_lon']\n",
       "df_test['dist_2d'] = np.sqrt(df_test['err_lat']**2 + df_test['err_lon']**2)\n",
       "\n",
       "print(\"Estatísticas gerais dos erros:\")\n",
       "print(df_test[['err_lat','err_lon','dist_2d']].describe())"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "### 5) Gráficos simplificados\n",
       "\n",
       "## 5.1 Histogramas (com escala completa e com zoom na região central)\n",
       "\n",
       "limite_err = 5  # Foco para erros entre -5 e 5\n",
       "limite_dist = 5  # Foco para a distância 2D de 0 até 5 m\n",
       "\n",
       "plt.figure(figsize=(16, 4))\n",
       "\n",
       "# Histograma do erro de latitude - escala completa\n",
       "plt.subplot(1, 3, 1)\n",
       "plt.hist(df_test['err_lat'], bins=30, color='skyblue', edgecolor='black')\n",
       "plt.title('Erro Latitude (Completo)')\n",
       "plt.xlabel('Erro (pred - real)')\n",
       "plt.ylabel('Frequência')\n",
       "\n",
       "# Histograma do erro de latitude - zoom\n",
       "plt.subplot(1, 3, 2)\n",
       "plt.hist(df_test['err_lat'], bins=30, range=(-limite_err, limite_err), color='skyblue', edgecolor='black')\n",
       "plt.title(f'Erro Latitude (Zoom: ±{limite_err} m)')\n",
       "plt.xlabel('Erro (pred - real)')\n",
       "\n",
       "# Histograma da distância 2D - zoom\n",
       "plt.subplot(1, 3, 3)\n",
       "plt.hist(df_test['dist_2d'], bins=30, range=(0, limite_dist), color='salmon', edgecolor='black')\n",
       "plt.title(f'Distância 2D (Zoom: 0 a {limite_dist} m)')\n",
       "plt.xlabel('Distância (m)')\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.show()\n",
       "\n",
       "## 5.2 Gráficos de densidade (KDE)\n",
       "\n",
       "plt.figure(figsize=(16, 4))\n",
       "\n",
       "plt.subplot(1, 3, 1)\n",
       "sns.kdeplot(df_test['err_lat'], shade=True, color='skyblue')\n",
       "plt.title('Densidade do Erro Latitude')\n",
       "plt.xlabel('Erro (pred - real)')\n",
       "\n",
       "plt.subplot(1, 3, 2)\n",
       "sns.kdeplot(df_test['err_lon'], shade=True, color='lightgreen')\n",
       "plt.title('Densidade do Erro Longitude')\n",
       "plt.xlabel('Erro (pred - real)')\n",
       "\n",
       "plt.subplot(1, 3, 3)\n",
       "sns.kdeplot(df_test['dist_2d'], shade=True, color='salmon')\n",
       "plt.title('Densidade da Distância 2D')\n",
       "plt.xlabel('Distância (m)')\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.show()\n",
       "\n",
       "## 5.3 Gráfico de dispersão: Valores Reais vs. Preditados para Latitude\n",
       "plt.figure(figsize=(7, 6))\n",
       "plt.scatter(df_test['real_lat'], df_test['pred_lat'], s=1, alpha=0.5, color='blue')\n",
       "plt.plot([df_test['real_lat'].min(), df_test['real_lat'].max()], \n",
       "         [df_test['real_lat'].min(), df_test['real_lat'].max()], \n",
       "         color='red', linestyle='--', label='Ideal (y=x)')\n",
       "plt.title('Predito vs. Real (Latitude)')\n",
       "plt.xlabel('Valor Real')\n",
       "plt.ylabel('Valor Predito')\n",
       "plt.legend()\n",
       "plt.show()\n",
       "\n",
       "## 5.4 Boxplots estratificados por faixa de latitude\n",
       "\n",
       "# Criar 5 faixas com base em 'real_lat'\n",
       "bins = np.linspace(df_test['real_lat'].min(), df_test['real_lat'].max(), 6)\n",
       "df_test['faixa'] = pd.cut(df_test['real_lat'], bins=bins, include_lowest=True)\n",
       "\n",
       "plt.figure(figsize=(12, 4))\n",
       "\n",
       "plt.subplot(1, 2, 1)\n",
       "sns.boxplot(x='faixa', y='err_lat', data=df_test, palette='Blues')\n",
       "plt.xticks(rotation=45)\n",
       "plt.title('Boxplot do Erro de Latitude por Faixa')\n",
       "plt.xlabel(\"Faixa de 'real_lat'\")\n",
       "plt.ylabel('Erro Latitude')\n",
       "\n",
       "plt.subplot(1, 2, 2)\n",
       "sns.boxplot(x='faixa', y='dist_2d', data=df_test, palette='Oranges')\n",
       "plt.xticks(rotation=45)\n",
       "plt.title('Boxplot da Distância 2D por Faixa')\n",
       "plt.xlabel(\"Faixa de 'real_lat'\")\n",
       "plt.ylabel('Distância 2D (m)')\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 6) Estratificação adicional e estatísticas por faixa\n",
       "\n",
       "df_group = df_test.groupby('faixa')['dist_2d'].describe()\n",
       "print(\"Estatísticas por faixa (real_lat) para a distância 2D:\")\n",
       "display(df_group)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Conclusão\n",
       "\n",
       "Neste notebook simplificado, avaliamos o modelo salvo usando métricas e geramos gráficos para analisar a distribuição dos erros. Foram incluídos histogramas com e sem zoom para evidenciar que a maioria dos erros está próxima de zero, gráficos de densidade para visualizar a concentração dos erros, um gráfico de dispersão (valores reais versus preditos) para verificar o alinhamento das predições, e boxplots estratificados por faixa de latitude para identificar possíveis diferenças regionais. \n",
       "\n",
       "Essas visualizações permitem uma análise mais detalhada dos resultados, facilitando a identificação dos casos extremos (outliers) e a verificação se o modelo tem um desempenho consistente em diferentes faixas de latitude."
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.11.4"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }
   