{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7_Normalize_vetor.ipynb (Melhorado)\n",
    "\n",
    "Este notebook processa o arquivo JSON (`Dataset_Grouped.json`) e:\n",
    "\n",
    "1. **Carrega o arquivo JSON de entrada**: Utiliza a biblioteca `json` para ler os dados do arquivo `Dataset_Grouped.json`.\n",
    "2. **Inicializa uma estrutura para os dados normalizados**: Cria uma lista vazia `normalized_data` que armazenará as entradas normalizadas.\n",
    "3. **Itera sobre cada entrada no dataset**:\n",
    "    - **Extrai e copia os campos globais**: Para cada entrada, copia campos como `altitude`, `accuracy`, `speed`, `bearing`, `timestamp`, `diferencalatitudeMetros` e `diferencalongitudeMetros` para uma nova estrutura `normalized_entry`.\n",
    "    - **Normaliza as informações das constelações de satélites**:\n",
    "        - Percorre cada tipo de constelação presente no campo `satellites`.\n",
    "        - Para cada satélite dentro da constelação, extrai o `svid` (identificador do satélite) e outros parâmetros como `azimuthDegrees`, `elevationDegrees`, `cn0DbHz`, `basebandCn0DbHz` e `carrierFrequencyHz`.\n",
    "        - Adiciona esses parâmetros à `normalized_entry` com chaves formatadas para facilitar o acesso e análise futura.\n",
    "4. **Adiciona a entrada normalizada à lista**: Após processar todos os satélites de uma entrada, adiciona a `normalized_entry` à lista `normalized_data`.\n",
    "5. **Salva os dados normalizados em um novo arquivo JSON**: Escreve a lista `normalized_data` no arquivo `Dataset_Vetor.json` com uma formatação indentada para melhor legibilidade.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo normalizado salvo em: ../TABELAS/JSONS/Dataset_Vetor.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Caminho do arquivo de entrada e saída\n",
    "input_file = \"../TABELAS/JSONS/Dataset_Grouped.json\"\n",
    "output_file = \"../TABELAS/JSONS/Dataset_Vetor.json\"\n",
    "\n",
    "def normalize_json(input_path, output_path):\n",
    "    with open(input_path, \"r\") as infile:\n",
    "        data = json.load(infile)\n",
    "\n",
    "    normalized_data = []\n",
    "\n",
    "    for entry in data:\n",
    "        # Copiar os campos globais\n",
    "        normalized_entry = {\n",
    "            \"altitude\": entry[\"altitude\"],\n",
    "            \"accuracy\": entry[\"accuracy\"],\n",
    "            \"speed\": entry[\"speed\"],\n",
    "            \"bearing\": entry[\"bearing\"],\n",
    "            \"timestamp\": entry[\"timestamp\"],\n",
    "            \"diferencalatitudeMetros\": entry[\"diferencalatitudeMetros\"],\n",
    "            \"diferencalongitudeMetros\": entry[\"diferencalongitudeMetros\"]\n",
    "        }\n",
    "\n",
    "        # Normalizar as constelações\n",
    "        for constellation_type, satellites in entry[\"satellites\"].items():\n",
    "            for sat in satellites:\n",
    "                svid = sat.get(\"svid\", 0)\n",
    "                normalized_entry[f\"{constellation_type}-svid\"] = svid\n",
    "                normalized_entry[f\"{constellation_type}-svid{svid}-azimuthDegrees\"] = sat.get(\"azimuthDegrees\", 0)\n",
    "                normalized_entry[f\"{constellation_type}-svid{svid}-elevationDegrees\"] = sat.get(\"elevationDegrees\", 0)\n",
    "                normalized_entry[f\"{constellation_type}-svid{svid}-cn0DbHz\"] = sat.get(\"cn0DbHz\", 0)\n",
    "                normalized_entry[f\"{constellation_type}-svid{svid}-basebandCn0DbHz\"] = sat.get(\"basebandCn0DbHz\", 0)\n",
    "                normalized_entry[f\"{constellation_type}-svid{svid}-carrierFrequencyHz\"] = sat.get(\"carrierFrequencyHz\", 0)\n",
    "\n",
    "        normalized_data.append(normalized_entry)\n",
    "\n",
    "    # Salvar o JSON normalizado\n",
    "    with open(output_path, \"w\") as outfile:\n",
    "        json.dump(normalized_data, outfile, indent=4)\n",
    "\n",
    "# Executar a normalização\n",
    "normalize_json(input_file, output_file)\n",
    "\n",
    "print(f\"Arquivo normalizado salvo em: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
