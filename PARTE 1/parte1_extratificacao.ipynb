{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e9c96bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dataset...\n",
      "‚úÖ Dataset carregado: 419,878 registros, 647 colunas\n",
      "‚úÖ Ap√≥s limpeza (NaN/inf): 419,878 registros\n",
      "\n",
      "=== RESUMO LATITUDE (m) ===\n",
      "                       n  mean(m)  median(m)    std(m)   var(m^2)  min(m)  p1(m)  p5(m)  p10(m)  p25(m)  p50(m)  p75(m)  p90(m)  p95(m)  p99(m)  max(m)  iqr(m)    mad(m)   MAE(m)   MSE(m^2)   RMSE(m)  R2(baseline_0)  outliers_tukey(n)  outliers_tukey(%)  perc_|e|<=0.5m  perc_|e|<=1m  perc_|e|<=2m  perc_|e|<=3m  perc_|e|<=5m  perc_|e|<=10m  perc_|e|<=20m  perc_|e|<=50m  perc_|e|<=100m\n",
      "latitude_erro(m)  419878   2.5426       2.11  5.414513  29.316953  -87.88  -5.69  -2.46   -1.58    0.51    2.11     4.7    6.58    7.57    19.8    78.2    4.19  2.907784  3.55032  35.781699  5.981781       -0.220515               9424             2.2445         10.0572       18.0324       40.8157       57.5015        75.681        98.1028        98.6891        99.8128           100.0\n",
      "\n",
      "--- Distribui√ß√£o por faixas (|erro| em m) LATITUDE ---\n",
      "bin_abs_error(m)  count  perc(%)\n",
      "           <=0.5  42228  10.0572\n",
      "           0.5‚Äì1  33486   7.9752\n",
      "             1‚Äì2  95662  22.7833\n",
      "             2‚Äì3  70060  16.6858\n",
      "             3‚Äì5  76332  18.1796\n",
      "            5‚Äì10  94144  22.4218\n",
      "           10‚Äì20   2462   0.5864\n",
      "           20‚Äì50   4718   1.1237\n",
      "          50‚Äì100    786   0.1872\n",
      "            >100      0   0.0000\n",
      "\n",
      "=== RESUMO LONGITUDE (m) ===\n",
      "                        n   mean(m)  median(m)    std(m)   var(m^2)  min(m)  p1(m)  p5(m)  p10(m)  p25(m)  p50(m)  p75(m)  p90(m)  p95(m)  p99(m)  max(m)  iqr(m)    mad(m)   MAE(m)   MSE(m^2)   RMSE(m)  R2(baseline_0)  outliers_tukey(n)  outliers_tukey(%)  perc_|e|<=0.5m  perc_|e|<=1m  perc_|e|<=2m  perc_|e|<=3m  perc_|e|<=5m  perc_|e|<=10m  perc_|e|<=20m  perc_|e|<=50m  perc_|e|<=100m\n",
      "longitude_erro(m)  419878  0.102123       -0.1  6.717824  45.129153 -124.37  -8.04  -3.41   -2.48   -1.21    -0.1    1.23    2.24     2.9    24.8  134.16    2.44  2.270169  2.26108  45.139475  6.718592       -0.000231              16990             4.0464         21.1714       42.3928       69.3668       88.8172       95.9869        97.6869        98.5129        99.4141         99.9562\n",
      "\n",
      "--- Distribui√ß√£o por faixas (|erro| em m) LONGITUDE ---\n",
      "bin_abs_error(m)  count  perc(%)\n",
      "           <=0.5  88894  21.1714\n",
      "           0.5‚Äì1  89104  21.2214\n",
      "             1‚Äì2 113258  26.9740\n",
      "             2‚Äì3  81668  19.4504\n",
      "             3‚Äì5  30104   7.1697\n",
      "            5‚Äì10   7138   1.7000\n",
      "           10‚Äì20   3468   0.8260\n",
      "           20‚Äì50   3784   0.9012\n",
      "          50‚Äì100   2276   0.5421\n",
      "            >100    184   0.0438\n",
      "\n",
      "=== RESUMO ERRO RADIAL (m) ===\n",
      "                     n   mean(m)  median(m)    std(m)   var(m^2)  min(m)     p1(m)     p5(m)    p10(m)    p25(m)    p50(m)    p75(m)    p90(m)    p95(m)     p99(m)      max(m)    iqr(m)  mad(m)    MAE(m)   MSE(m^2)  RMSE(m)  R2(baseline_0)  outliers_tukey(n)  outliers_tukey(%)  perc_|e|<=0.5m  perc_|e|<=1m  perc_|e|<=2m  perc_|e|<=3m  perc_|e|<=5m  perc_|e|<=10m  perc_|e|<=20m  perc_|e|<=50m  perc_|e|<=100m\n",
      "erro_radial(m)  419878  4.615833   3.206649  7.721101  59.615402    0.25  0.516236  0.864002  1.192057  1.971852  3.206649  5.572298  6.871448  8.293063  43.221676  152.591597  3.600446  2.9754  4.615833  80.921174  8.99562        -0.35739              10914             2.5993          0.9641        6.9134       25.8766       47.4262        71.879        97.3583        97.8275        99.2322         99.9305\n",
      "\n",
      "--- Distribui√ß√£o por faixas (erro radial em m) ---\n",
      "bin_abs_error(m)  count  perc(%)\n",
      "           <=0.5   4048   0.9641\n",
      "           0.5‚Äì1  24980   5.9493\n",
      "             1‚Äì2  79622  18.9631\n",
      "             2‚Äì3  90482  21.5496\n",
      "             3‚Äì5 102672  24.4528\n",
      "            5‚Äì10 106982  25.4793\n",
      "           10‚Äì20   1970   0.4692\n",
      "           20‚Äì50   5898   1.4047\n",
      "          50‚Äì100   2932   0.6983\n",
      "            >100    292   0.0695\n",
      "\n",
      "=== CORRELA√á√ÉO LAT √ó LON ===\n",
      "      metric     value\n",
      "   pearson_r  0.431028\n",
      "spearman_rho -0.152977\n",
      "     var_lat 29.316953\n",
      "     var_lon 45.129153\n",
      " cov_lat_lon 15.678093\n",
      "\n",
      "=== QUADRANTES (sinais de lat/lon) ===\n",
      "    quadrante  perc(%)\n",
      "Q1(+lat,+lon)  40.2364\n",
      "Q2(+lat,-lon)  41.8007\n",
      "Q3(-lat,-lon)  11.0923\n",
      "Q4(-lat,+lon)   6.8706\n",
      "\n",
      "=== ESTRATIFICA√á√ÉO TEMPORAL (timestamp em quintis) ===\n",
      "\n",
      "‚Äî LAT por tempo ‚Äî\n",
      "                     n      mean  median       std       MAE        MSE      RMSE\n",
      "_bucket_tempo                                                                    \n",
      "Q1             83980.0 -0.787131   -1.15  4.028294  1.944368  16.846534  4.104453\n",
      "Q2             83982.0  1.620261    1.43  3.592873  1.934127  15.533828  3.941298\n",
      "Q3             83970.0  2.401536    2.11  5.251327  3.163860  33.343481  5.774381\n",
      "Q4             83980.0  3.565067    3.59  6.203827  4.339043  51.196713  7.155188\n",
      "Q5             83966.0  5.913835    6.03  5.198016  6.370664  61.992502  7.873532\n",
      "\n",
      "‚Äî LON por tempo ‚Äî\n",
      "                     n      mean  median       std       MAE        MSE      RMSE\n",
      "_bucket_tempo                                                                    \n",
      "Q1             83980.0 -0.833397   -0.66  5.000742  1.912985  25.701679  5.069682\n",
      "Q2             83982.0  1.671286    1.42  4.884174  2.094047  26.648065  5.162176\n",
      "Q3             83970.0  0.539417    0.46  7.082391  2.207449  50.450629  7.102861\n",
      "Q4             83980.0 -0.437553   -0.54  8.409010  2.641640  70.902058  8.420336\n",
      "Q5             83966.0 -0.429215   -0.72  7.198163  2.449307  51.997159  7.210906\n",
      "\n",
      "‚Äî RADIAL por tempo ‚Äî\n",
      "                     n      mean    median       std       MAE         MSE       RMSE\n",
      "_bucket_tempo                                                                        \n",
      "Q1             83980.0  2.963500  1.907800  5.810876  2.963500   42.548213   6.522899\n",
      "Q2             83982.0  3.058202  2.434297  5.729720  3.058202   42.181893   6.494759\n",
      "Q3             83970.0  4.243994  2.768483  8.110697  4.243994   83.794109   9.153912\n",
      "Q4             83980.0  5.526448  4.246045  9.568607  5.526448  122.098771  11.049831\n",
      "Q5             83966.0  7.287460  6.132414  7.802776  7.287460  113.989661  10.676594\n",
      "\n",
      "üíæ Arquivos salvos em: D:\\[TCC]\\CODE\\parte1_resultados_sem_graficos\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "An√°lise e estratifica√ß√£o pr√©-RNA (SEM GR√ÅFICOS)\n",
    "Base: Dataset_Vetor.json\n",
    "Foco: erros em metros de latitude, longitude e erro radial\n",
    "N√ÉO altera nomes/colunas do dataset.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# Configura√ß√£o e carregamento\n",
    "# =========================\n",
    "JSON_PATH = \"Dataset_Vetor.json\"  # ajuste se necess√°rio\n",
    "OUTPUT_DIR = Path(\"./parte1_resultados_sem_graficos\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Carregando dataset...\")\n",
    "with open(JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"‚úÖ Dataset carregado: {len(df):,} registros, {df.shape[1]} colunas\")\n",
    "\n",
    "# =========================\n",
    "# Colunas de erro (N√ÉO renomear)\n",
    "# =========================\n",
    "lat_col = \"diferencalatitudeMetros\"\n",
    "lon_col = \"diferencalongitudeMetros\"\n",
    "\n",
    "missing_cols = [c for c in [lat_col, lon_col] if c not in df.columns]\n",
    "if missing_cols:\n",
    "    raise KeyError(f\"As colunas esperadas n√£o existem no dataset: {missing_cols}\")\n",
    "\n",
    "# Garantir tipos num√©ricos e remover NaNs/inf\n",
    "for c in [lat_col, lon_col]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=[lat_col, lon_col]).copy()\n",
    "print(f\"‚úÖ Ap√≥s limpeza (NaN/inf): {len(df):,} registros\")\n",
    "\n",
    "# =========================\n",
    "# Fun√ß√µes utilit√°rias\n",
    "# =========================\n",
    "def tukey_limits(series: pd.Series):\n",
    "    q1, q3 = np.percentile(series, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    return q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "\n",
    "def summarize_errors(y: pd.Series, name: str) -> pd.DataFrame:\n",
    "    \"\"\"Resumo estat√≠stico + m√©tricas de erro quadr√°ticas (baseline 0).\"\"\"\n",
    "    y = pd.to_numeric(y, errors=\"coerce\").dropna()\n",
    "    n = y.size\n",
    "    if n == 0:\n",
    "        raise ValueError(f\"Sem dados v√°lidos para {name}.\")\n",
    "\n",
    "    # Estat√≠sticas b√°sicas\n",
    "    mean = y.mean()\n",
    "    median = y.median()\n",
    "    std = y.std(ddof=1)\n",
    "    var = y.var(ddof=1)\n",
    "    mn = y.min()\n",
    "    mx = y.max()\n",
    "    q = y.quantile([0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99])\n",
    "    iqr = q.loc[0.75] - q.loc[0.25]\n",
    "    mad = (y - mean).abs().mean()  # mean absolute deviation em rela√ß√£o √† m√©dia\n",
    "\n",
    "    # M√©tricas de erro (baseline 0)\n",
    "    abs_y = y.abs()\n",
    "    mae = abs_y.mean()\n",
    "    mse = (y ** 2).mean()\n",
    "    rmse = math.sqrt(mse)\n",
    "\n",
    "    # R¬≤ do baseline 0 (pode ser negativo; √∫til para refer√™ncia)\n",
    "    # R¬≤ = 1 - SSE/SST, com SSE = sum((y-0)^2) e SST = sum((y-mean)^2)\n",
    "    sse = (y ** 2).sum()\n",
    "    sst = ((y - mean) ** 2).sum()\n",
    "    r2_baseline0 = float(\"nan\") if sst == 0 else 1 - (sse / sst)\n",
    "\n",
    "    # Outliers (Tukey)\n",
    "    low, high = tukey_limits(y)\n",
    "    outliers = ((y < low) | (y > high)).sum()\n",
    "\n",
    "    # Faixas de erro (limiares em metros)\n",
    "    thresholds = [0.5, 1, 2, 3, 5, 10, 20, 50, 100]\n",
    "    within = {f\"perc_|e|<={t}m\": (abs_y.le(t).mean() * 100.0) for t in thresholds}\n",
    "\n",
    "    # Bins por magnitude do erro absoluto\n",
    "    # Ajuste as bordas se desejar granularidade diferente\n",
    "    bins = [-np.inf, 0.5, 1, 2, 3, 5, 10, 20, 50, 100, np.inf]\n",
    "    labels = [\"<=0.5\", \"0.5‚Äì1\", \"1‚Äì2\", \"2‚Äì3\", \"3‚Äì5\", \"5‚Äì10\", \"10‚Äì20\", \"20‚Äì50\", \"50‚Äì100\", \">100\"]\n",
    "    dist_bins = pd.cut(abs_y, bins=bins, labels=labels, include_lowest=True)\n",
    "    bin_counts = dist_bins.value_counts().reindex(labels).fillna(0).astype(int)\n",
    "    bin_perc = (bin_counts / n * 100).round(4)\n",
    "\n",
    "    # Monta DataFrame de m√©tricas\n",
    "    summary = {\n",
    "        \"n\": n,\n",
    "        \"mean(m)\": mean,\n",
    "        \"median(m)\": median,\n",
    "        \"std(m)\": std,\n",
    "        \"var(m^2)\": var,\n",
    "        \"min(m)\": mn,\n",
    "        \"p1(m)\": q.loc[0.01],\n",
    "        \"p5(m)\": q.loc[0.05],\n",
    "        \"p10(m)\": q.loc[0.10],\n",
    "        \"p25(m)\": q.loc[0.25],\n",
    "        \"p50(m)\": q.loc[0.50],\n",
    "        \"p75(m)\": q.loc[0.75],\n",
    "        \"p90(m)\": q.loc[0.90],\n",
    "        \"p95(m)\": q.loc[0.95],\n",
    "        \"p99(m)\": q.loc[0.99],\n",
    "        \"max(m)\": mx,\n",
    "        \"iqr(m)\": iqr,\n",
    "        \"mad(m)\": mad,\n",
    "        \"MAE(m)\": mae,\n",
    "        \"MSE(m^2)\": mse,\n",
    "        \"RMSE(m)\": rmse,\n",
    "        \"R2(baseline_0)\": r2_baseline0,\n",
    "        \"outliers_tukey(n)\": int(outliers),\n",
    "        \"outliers_tukey(%)\": round(outliers / n * 100.0, 4),\n",
    "    }\n",
    "    summary.update({k: round(v, 4) for k, v in within.items()})\n",
    "\n",
    "    # Retorna duas tabelas: (1) m√©tricas gerais, (2) distribui√ß√£o por bins\n",
    "    summary_df = pd.DataFrame(summary, index=[name])\n",
    "    bins_df = pd.DataFrame({\n",
    "        \"bin_abs_error(m)\": labels,\n",
    "        \"count\": bin_counts.values,\n",
    "        \"perc(%)\": bin_perc.values\n",
    "    })\n",
    "    return summary_df, bins_df\n",
    "\n",
    "def quadrant_breakdown(lat: pd.Series, lon: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"Percentual por quadrante do plano (sinal de lat/lon).\"\"\"\n",
    "    q1 = ((lat >= 0) & (lon >= 0)).mean() * 100\n",
    "    q2 = ((lat >= 0) & (lon < 0)).mean() * 100\n",
    "    q3 = ((lat < 0) & (lon < 0)).mean() * 100\n",
    "    q4 = ((lat < 0) & (lon >= 0)).mean() * 100\n",
    "    return pd.DataFrame({\n",
    "        \"quadrante\": [\"Q1(+lat,+lon)\", \"Q2(+lat,-lon)\", \"Q3(-lat,-lon)\", \"Q4(-lat,+lon)\"],\n",
    "        \"perc(%)\": [round(q1, 4), round(q2, 4), round(q3, 4), round(q4, 4)]\n",
    "    })\n",
    "\n",
    "def correlation_summary(lat: pd.Series, lon: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"Correla√ß√£o entre erros lat/lon e vari√¢ncias.\"\"\"\n",
    "    lat = pd.to_numeric(lat, errors=\"coerce\")\n",
    "    lon = pd.to_numeric(lon, errors=\"coerce\")\n",
    "    mask = lat.notna() & lon.notna()\n",
    "    lat = lat[mask]\n",
    "    lon = lon[mask]\n",
    "    pearson = float(pd.Series(lat).corr(pd.Series(lon), method=\"pearson\"))\n",
    "    spearman = float(pd.Series(lat).corr(pd.Series(lon), method=\"spearman\"))\n",
    "    return pd.DataFrame({\n",
    "        \"metric\": [\"pearson_r\", \"spearman_rho\", \"var_lat\", \"var_lon\", \"cov_lat_lon\"],\n",
    "        \"value\": [\n",
    "            round(pearson, 6),\n",
    "            round(spearman, 6),\n",
    "            round(lat.var(ddof=1), 6),\n",
    "            round(lon.var(ddof=1), 6),\n",
    "            round(np.cov(lat, lon, ddof=1)[0, 1], 6),\n",
    "        ]\n",
    "    })\n",
    "\n",
    "# =========================\n",
    "# 1) AN√ÅLISE LATITUDE (erro em metros)\n",
    "# =========================\n",
    "lat_summary, lat_bins = summarize_errors(df[lat_col], name=\"latitude_erro(m)\")\n",
    "lat_summary.to_csv(OUTPUT_DIR / \"stats_latitude.csv\", index=True)\n",
    "lat_bins.to_csv(OUTPUT_DIR / \"bins_latitude.csv\", index=False)\n",
    "\n",
    "print(\"\\n=== RESUMO LATITUDE (m) ===\")\n",
    "print(lat_summary.to_string())\n",
    "print(\"\\n--- Distribui√ß√£o por faixas (|erro| em m) LATITUDE ---\")\n",
    "print(lat_bins.to_string(index=False))\n",
    "\n",
    "# =========================\n",
    "# 2) AN√ÅLISE LONGITUDE (erro em metros)\n",
    "# =========================\n",
    "lon_summary, lon_bins = summarize_errors(df[lon_col], name=\"longitude_erro(m)\")\n",
    "lon_summary.to_csv(OUTPUT_DIR / \"stats_longitude.csv\", index=True)\n",
    "lon_bins.to_csv(OUTPUT_DIR / \"bins_longitude.csv\", index=False)\n",
    "\n",
    "print(\"\\n=== RESUMO LONGITUDE (m) ===\")\n",
    "print(lon_summary.to_string())\n",
    "print(\"\\n--- Distribui√ß√£o por faixas (|erro| em m) LONGITUDE ---\")\n",
    "print(lon_bins.to_string(index=False))\n",
    "\n",
    "# =========================\n",
    "# 3) ERRO RADIAL (m) + RELA√á√ÉO LAT √ó LON\n",
    "# =========================\n",
    "# Erro radial em metros (hipotenusa): sqrt(lat^2 + lon^2)\n",
    "df[\"erro_radial_m\"] = np.sqrt(df[lat_col]**2 + df[lon_col]**2)\n",
    "\n",
    "rad_summary, rad_bins = summarize_errors(df[\"erro_radial_m\"], name=\"erro_radial(m)\")\n",
    "rad_summary.to_csv(OUTPUT_DIR / \"stats_erro_radial.csv\", index=True)\n",
    "rad_bins.to_csv(OUTPUT_DIR / \"bins_erro_radial.csv\", index=False)\n",
    "\n",
    "print(\"\\n=== RESUMO ERRO RADIAL (m) ===\")\n",
    "print(rad_summary.to_string())\n",
    "print(\"\\n--- Distribui√ß√£o por faixas (erro radial em m) ---\")\n",
    "print(rad_bins.to_string(index=False))\n",
    "\n",
    "# Correla√ß√£o e quadrantes\n",
    "corr_df = correlation_summary(df[lat_col], df[lon_col])\n",
    "corr_df.to_csv(OUTPUT_DIR / \"correlacao_lat_lon.csv\", index=False)\n",
    "\n",
    "quads_df = quadrant_breakdown(df[lat_col], df[lon_col])\n",
    "quads_df.to_csv(OUTPUT_DIR / \"quadrantes_lat_lon.csv\", index=False)\n",
    "\n",
    "print(\"\\n=== CORRELA√á√ÉO LAT √ó LON ===\")\n",
    "print(corr_df.to_string(index=False))\n",
    "print(\"\\n=== QUADRANTES (sinais de lat/lon) ===\")\n",
    "print(quads_df.to_string(index=False))\n",
    "\n",
    "# =========================\n",
    "# 4) (Opcional) Estratifica√ß√£o temporal simples (se existir 'timestamp' normalizado)\n",
    "#     ‚Äì Sem gr√°ficos; apenas m√©tricas por faixas de tempo\n",
    "# =========================\n",
    "if \"timestamp\" in df.columns:\n",
    "    # Exemplo de bucketing: quintis (ou defina manualmente buckets de hora)\n",
    "    df[\"_bucket_tempo\"] = pd.qcut(df[\"timestamp\"], q=5, labels=[f\"Q{i}\" for i in range(1, 6)])\n",
    "    group_cols = [\"_bucket_tempo\"]\n",
    "\n",
    "    def group_metrics(series: pd.Series) -> pd.Series:\n",
    "        series = pd.to_numeric(series, errors=\"coerce\").dropna()\n",
    "        return pd.Series({\n",
    "            \"n\": series.size,\n",
    "            \"mean\": series.mean(),\n",
    "            \"median\": series.median(),\n",
    "            \"std\": series.std(ddof=1),\n",
    "            \"MAE\": series.abs().mean(),\n",
    "            \"MSE\": (series**2).mean(),\n",
    "            \"RMSE\": math.sqrt((series**2).mean()),\n",
    "        })\n",
    "\n",
    "    lat_by_time = df.groupby(group_cols)[lat_col].apply(group_metrics).unstack()\n",
    "    lon_by_time = df.groupby(group_cols)[lon_col].apply(group_metrics).unstack()\n",
    "    rad_by_time = df.groupby(group_cols)[\"erro_radial_m\"].apply(group_metrics).unstack()\n",
    "\n",
    "    lat_by_time.to_csv(OUTPUT_DIR / \"lat_por_tempo.csv\")\n",
    "    lon_by_time.to_csv(OUTPUT_DIR / \"lon_por_tempo.csv\")\n",
    "    rad_by_time.to_csv(OUTPUT_DIR / \"radial_por_tempo.csv\")\n",
    "\n",
    "    print(\"\\n=== ESTRATIFICA√á√ÉO TEMPORAL (timestamp em quintis) ===\")\n",
    "    print(\"\\n‚Äî LAT por tempo ‚Äî\")\n",
    "    print(lat_by_time.to_string())\n",
    "    print(\"\\n‚Äî LON por tempo ‚Äî\")\n",
    "    print(lon_by_time.to_string())\n",
    "    print(\"\\n‚Äî RADIAL por tempo ‚Äî\")\n",
    "    print(rad_by_time.to_string())\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Coluna 'timestamp' n√£o encontrada. Pulo da estratifica√ß√£o temporal.\")\n",
    "\n",
    "# =========================\n",
    "# 5) Export b√°sico do describe num√©rico (apoio)\n",
    "# =========================\n",
    "num_desc = df.select_dtypes(include=[np.number]).describe().T\n",
    "num_desc.to_csv(OUTPUT_DIR / \"describe_numeric.csv\", index=True)\n",
    "print(\"\\nüíæ Arquivos salvos em:\", OUTPUT_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "369d6037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dataset...\n",
      "‚úÖ Dataset carregado: 419,878 registros, 647 colunas\n",
      "‚úÖ Ap√≥s limpeza: 419,878 registros v√°lidos\n",
      "periodo\n",
      "manha    214258\n",
      "tarde    205620\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üîπ Analisando per√≠odo: MANHA (214,258 registros)\n",
      "\n",
      "--- LAT ---\n",
      "                           n   mean(m)  median(m)    std(m)   var(m^2)  min(m)  p25(m)  p50(m)  p75(m)  max(m)  iqr(m)    mad(m)    MAE(m)   MSE(m^2)   RMSE(m)  R2(baseline_0)  outliers_tukey(n)  outliers_tukey(%)  perc_|e|<=0.5m  perc_|e|<=1m  perc_|e|<=2m  perc_|e|<=3m  perc_|e|<=5m  perc_|e|<=10m  perc_|e|<=20m  perc_|e|<=50m  perc_|e|<=100m\n",
      "latitude_erro(manha)  214258  0.559631       0.83  4.099707  16.807597  -87.88   -0.84    0.83    1.57   74.74    2.41  1.783481  1.919722  17.120705  4.137717       -0.018634               5080              2.371         16.6706       28.6197       68.2747       89.8748       97.6729        98.4085        99.2075        99.8964           100.0\n",
      "\n",
      "--- LON ---\n",
      "                            n   mean(m)  median(m)    std(m)   var(m^2)  min(m)  p25(m)  p50(m)  p75(m)  max(m)  iqr(m)    mad(m)    MAE(m)   MSE(m^2)   RMSE(m)  R2(baseline_0)  outliers_tukey(n)  outliers_tukey(%)  perc_|e|<=0.5m  perc_|e|<=1m  perc_|e|<=2m  perc_|e|<=3m  perc_|e|<=5m  perc_|e|<=10m  perc_|e|<=20m  perc_|e|<=50m  perc_|e|<=100m\n",
      "longitude_erro(manha)  214258  0.591069       0.39  5.191973  26.956581 -124.37   -0.66    0.39    1.69  134.16    2.35  1.945782  1.969498  27.305817  5.225497        -0.01296              10898             5.0864         21.6963       42.1417       70.5598       89.0609       95.8387        98.1854        99.0703        99.6565         99.9683\n",
      "\n",
      "--- RADIAL ---\n",
      "                         n  mean(m)  median(m)    std(m)   var(m^2)    min(m)    p25(m)    p50(m)    p75(m)      max(m)    iqr(m)    mad(m)  MAE(m)   MSE(m^2)   RMSE(m)  R2(baseline_0)  outliers_tukey(n)  outliers_tukey(%)  perc_|e|<=0.5m  perc_|e|<=1m  perc_|e|<=2m  perc_|e|<=3m  perc_|e|<=5m  perc_|e|<=10m  perc_|e|<=20m  perc_|e|<=50m  perc_|e|<=100m\n",
      "erro_radial(manha)  214258   2.9811   2.150814  5.961521  35.539731  0.313209  1.391294  2.150814  2.986051  152.591597  1.594757  1.815578  2.9811  44.426522  6.665322       -0.250058               9560             4.4619          0.7122        10.591       44.7078       75.7769       94.6942        97.8157        98.4747        99.5519         99.9599\n",
      "\n",
      "--- CORRELA√á√ÉO LAT √ó LON ---\n",
      "      metric     value\n",
      "   pearson_r  0.466461\n",
      "spearman_rho  0.410685\n",
      "     var_lat 16.807597\n",
      "     var_lon 26.956581\n",
      " cov_lat_lon  9.928890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_30748\\926002793.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_df[\"erro_radial_m\"] = np.sqrt(sub_df[lat_col]**2 + sub_df[lon_col]**2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Analisando per√≠odo: TARDE (205,620 registros)\n",
      "\n",
      "--- LAT ---\n",
      "                           n   mean(m)  median(m)    std(m)   var(m^2)  min(m)  p25(m)  p50(m)  p75(m)  max(m)  iqr(m)    mad(m)    MAE(m)   MSE(m^2)   RMSE(m)  R2(baseline_0)  outliers_tukey(n)  outliers_tukey(%)  perc_|e|<=0.5m  perc_|e|<=1m  perc_|e|<=2m  perc_|e|<=3m  perc_|e|<=5m  perc_|e|<=10m  perc_|e|<=20m  perc_|e|<=50m  perc_|e|<=100m\n",
      "latitude_erro(tarde)  205620  4.608874        4.7  5.829673  33.985083  -85.46    2.92     4.7    6.09    78.2    3.17  2.536258  5.249418  55.226633  7.431462       -0.625034               6644             3.2312           3.166        7.0003       12.2031       23.7681       52.7653        97.7843         98.149        99.7257           100.0\n",
      "\n",
      "--- LON ---\n",
      "                            n   mean(m)  median(m)    std(m)  var(m^2)  min(m)  p25(m)  p50(m)  p75(m)  max(m)  iqr(m)    mad(m)    MAE(m)   MSE(m^2)   RMSE(m)  R2(baseline_0)  outliers_tukey(n)  outliers_tukey(%)  perc_|e|<=0.5m  perc_|e|<=1m  perc_|e|<=2m  perc_|e|<=3m  perc_|e|<=5m  perc_|e|<=10m  perc_|e|<=20m  perc_|e|<=50m  perc_|e|<=100m\n",
      "longitude_erro(tarde)  205620 -0.407364      -0.62  7.972244  63.55668 -111.42   -1.84   -0.62    0.76  130.45     2.6  2.483763  2.564911  63.722316  7.982626       -0.002611               6436               3.13         20.6245       42.6544       68.1237       88.5634       96.1414        97.1676        97.9321        99.1616         99.9436\n",
      "\n",
      "--- RADIAL ---\n",
      "                         n  mean(m)  median(m)    std(m)   var(m^2)  min(m)    p25(m)    p50(m)    p75(m)      max(m)   iqr(m)    mad(m)   MAE(m)    MSE(m^2)    RMSE(m)  R2(baseline_0)  outliers_tukey(n)  outliers_tukey(%)  perc_|e|<=0.5m  perc_|e|<=1m  perc_|e|<=2m  perc_|e|<=3m  perc_|e|<=5m  perc_|e|<=10m  perc_|e|<=20m  perc_|e|<=50m  perc_|e|<=100m\n",
      "erro_radial(tarde)  205620  6.31924   5.171857  8.889125  79.016535    0.25  3.684698  5.171857  6.301468  149.883684  2.61677  3.109401  6.31924  118.948949  10.906372       -0.505375               6358             3.0921          1.2265        3.0814        6.2543       17.8844       48.1052        96.8816         97.153        98.8989         99.8998\n",
      "\n",
      "--- CORRELA√á√ÉO LAT √ó LON ---\n",
      "      metric     value\n",
      "   pearson_r  0.510632\n",
      "spearman_rho -0.297358\n",
      "     var_lat 33.985083\n",
      "     var_lon 63.556680\n",
      " cov_lat_lon 23.731938\n",
      "\n",
      "üíæ Resultados salvos em: D:\\[TCC]\\CODE\\parte1_resultados_periodos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_30748\\926002793.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_df[\"erro_radial_m\"] = np.sqrt(sub_df[lat_col]**2 + sub_df[lon_col]**2)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "An√°lise e estratifica√ß√£o pr√©-RNA por per√≠odo (MANH√É vs TARDE)\n",
    "Corte temporal: timestamp < 0.5 (manh√£) / >= 0.5 (tarde)\n",
    "Foco: m√©tricas de erro em metros (sem gr√°ficos)\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# Configura√ß√£o e carregamento\n",
    "# =========================\n",
    "JSON_PATH = \"Dataset_Vetor.json\"  # ajuste se necess√°rio\n",
    "BASE_OUTPUT = Path(\"./parte1_resultados_periodos\")\n",
    "BASE_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Carregando dataset...\")\n",
    "with open(JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"‚úÖ Dataset carregado: {len(df):,} registros, {df.shape[1]} colunas\")\n",
    "\n",
    "lat_col = \"diferencalatitudeMetros\"\n",
    "lon_col = \"diferencalongitudeMetros\"\n",
    "\n",
    "missing_cols = [c for c in [lat_col, lon_col, \"timestamp\"] if c not in df.columns]\n",
    "if missing_cols:\n",
    "    raise KeyError(f\"As colunas esperadas n√£o existem no dataset: {missing_cols}\")\n",
    "\n",
    "# Limpeza b√°sica\n",
    "for c in [lat_col, lon_col, \"timestamp\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=[lat_col, lon_col, \"timestamp\"])\n",
    "print(f\"‚úÖ Ap√≥s limpeza: {len(df):,} registros v√°lidos\")\n",
    "\n",
    "# =========================\n",
    "# Fun√ß√µes utilit√°rias\n",
    "# =========================\n",
    "def tukey_limits(series):\n",
    "    q1, q3 = np.percentile(series, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    return q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "\n",
    "def summarize_errors(y: pd.Series, name: str) -> pd.DataFrame:\n",
    "    y = pd.to_numeric(y, errors=\"coerce\").dropna()\n",
    "    n = len(y)\n",
    "    if n == 0:\n",
    "        raise ValueError(f\"Sem dados v√°lidos para {name}\")\n",
    "\n",
    "    mean = y.mean()\n",
    "    median = y.median()\n",
    "    std = y.std(ddof=1)\n",
    "    var = y.var(ddof=1)\n",
    "    mn = y.min()\n",
    "    mx = y.max()\n",
    "    q = y.quantile([0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99])\n",
    "    iqr = q.loc[0.75] - q.loc[0.25]\n",
    "    mad = (y - mean).abs().mean()\n",
    "\n",
    "    abs_y = y.abs()\n",
    "    mae = abs_y.mean()\n",
    "    mse = (y ** 2).mean()\n",
    "    rmse = math.sqrt(mse)\n",
    "\n",
    "    sse = (y ** 2).sum()\n",
    "    sst = ((y - mean) ** 2).sum()\n",
    "    r2_baseline0 = float(\"nan\") if sst == 0 else 1 - (sse / sst)\n",
    "\n",
    "    low, high = tukey_limits(y)\n",
    "    outliers = ((y < low) | (y > high)).sum()\n",
    "\n",
    "    thresholds = [0.5, 1, 2, 3, 5, 10, 20, 50, 100]\n",
    "    within = {f\"perc_|e|<={t}m\": abs_y.le(t).mean() * 100.0 for t in thresholds}\n",
    "\n",
    "    bins = [-np.inf, 0.5, 1, 2, 3, 5, 10, 20, 50, 100, np.inf]\n",
    "    labels = [\"<=0.5\", \"0.5‚Äì1\", \"1‚Äì2\", \"2‚Äì3\", \"3‚Äì5\", \"5‚Äì10\", \"10‚Äì20\", \"20‚Äì50\", \"50‚Äì100\", \">100\"]\n",
    "    dist_bins = pd.cut(abs_y, bins=bins, labels=labels, include_lowest=True)\n",
    "    bin_counts = dist_bins.value_counts().reindex(labels).fillna(0).astype(int)\n",
    "    bin_perc = (bin_counts / n * 100).round(4)\n",
    "\n",
    "    summary = {\n",
    "        \"n\": n,\n",
    "        \"mean(m)\": mean,\n",
    "        \"median(m)\": median,\n",
    "        \"std(m)\": std,\n",
    "        \"var(m^2)\": var,\n",
    "        \"min(m)\": mn,\n",
    "        \"p25(m)\": q.loc[0.25],\n",
    "        \"p50(m)\": q.loc[0.50],\n",
    "        \"p75(m)\": q.loc[0.75],\n",
    "        \"max(m)\": mx,\n",
    "        \"iqr(m)\": iqr,\n",
    "        \"mad(m)\": mad,\n",
    "        \"MAE(m)\": mae,\n",
    "        \"MSE(m^2)\": mse,\n",
    "        \"RMSE(m)\": rmse,\n",
    "        \"R2(baseline_0)\": r2_baseline0,\n",
    "        \"outliers_tukey(n)\": int(outliers),\n",
    "        \"outliers_tukey(%)\": round(outliers / n * 100.0, 4),\n",
    "    }\n",
    "    summary.update({k: round(v, 4) for k, v in within.items()})\n",
    "    summary_df = pd.DataFrame(summary, index=[name])\n",
    "\n",
    "    bins_df = pd.DataFrame({\n",
    "        \"bin_abs_error(m)\": labels,\n",
    "        \"count\": bin_counts.values,\n",
    "        \"perc(%)\": bin_perc.values\n",
    "    })\n",
    "    return summary_df, bins_df\n",
    "\n",
    "def correlation_summary(lat: pd.Series, lon: pd.Series) -> pd.DataFrame:\n",
    "    lat = pd.to_numeric(lat, errors=\"coerce\")\n",
    "    lon = pd.to_numeric(lon, errors=\"coerce\")\n",
    "    mask = lat.notna() & lon.notna()\n",
    "    lat, lon = lat[mask], lon[mask]\n",
    "    pearson = float(pd.Series(lat).corr(pd.Series(lon), method=\"pearson\"))\n",
    "    spearman = float(pd.Series(lat).corr(pd.Series(lon), method=\"spearman\"))\n",
    "    return pd.DataFrame({\n",
    "        \"metric\": [\"pearson_r\", \"spearman_rho\", \"var_lat\", \"var_lon\", \"cov_lat_lon\"],\n",
    "        \"value\": [\n",
    "            round(pearson, 6),\n",
    "            round(spearman, 6),\n",
    "            round(lat.var(ddof=1), 6),\n",
    "            round(lon.var(ddof=1), 6),\n",
    "            round(np.cov(lat, lon, ddof=1)[0, 1], 6),\n",
    "        ]\n",
    "    })\n",
    "\n",
    "# =========================\n",
    "# Separar per√≠odos (manh√£/tarde)\n",
    "# =========================\n",
    "df[\"periodo\"] = np.where(df[\"timestamp\"] < 0.5, \"manha\", \"tarde\")\n",
    "print(df[\"periodo\"].value_counts())\n",
    "\n",
    "# =========================\n",
    "# Fun√ß√£o de an√°lise por per√≠odo\n",
    "# =========================\n",
    "def analisar_periodo(sub_df: pd.DataFrame, periodo: str):\n",
    "    out_dir = BASE_OUTPUT / periodo\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"\\nüîπ Analisando per√≠odo: {periodo.upper()} ({len(sub_df):,} registros)\")\n",
    "\n",
    "    # Latitude\n",
    "    lat_summary, lat_bins = summarize_errors(sub_df[lat_col], f\"latitude_erro({periodo})\")\n",
    "    lat_summary.to_csv(out_dir / \"stats_latitude.csv\", index=True)\n",
    "    lat_bins.to_csv(out_dir / \"bins_latitude.csv\", index=False)\n",
    "\n",
    "    # Longitude\n",
    "    lon_summary, lon_bins = summarize_errors(sub_df[lon_col], f\"longitude_erro({periodo})\")\n",
    "    lon_summary.to_csv(out_dir / \"stats_longitude.csv\", index=True)\n",
    "    lon_bins.to_csv(out_dir / \"bins_longitude.csv\", index=False)\n",
    "\n",
    "    # Erro radial\n",
    "    sub_df[\"erro_radial_m\"] = np.sqrt(sub_df[lat_col]**2 + sub_df[lon_col]**2)\n",
    "    rad_summary, rad_bins = summarize_errors(sub_df[\"erro_radial_m\"], f\"erro_radial({periodo})\")\n",
    "    rad_summary.to_csv(out_dir / \"stats_erro_radial.csv\", index=True)\n",
    "    rad_bins.to_csv(out_dir / \"bins_erro_radial.csv\", index=False)\n",
    "\n",
    "    # Correla√ß√£o lat x lon\n",
    "    corr_df = correlation_summary(sub_df[lat_col], sub_df[lon_col])\n",
    "    corr_df.to_csv(out_dir / \"correlacao_lat_lon.csv\", index=False)\n",
    "\n",
    "    print(\"\\n--- LAT ---\")\n",
    "    print(lat_summary.to_string())\n",
    "    print(\"\\n--- LON ---\")\n",
    "    print(lon_summary.to_string())\n",
    "    print(\"\\n--- RADIAL ---\")\n",
    "    print(rad_summary.to_string())\n",
    "    print(\"\\n--- CORRELA√á√ÉO LAT √ó LON ---\")\n",
    "    print(corr_df.to_string(index=False))\n",
    "\n",
    "    # Salva resumo consolidado\n",
    "    combined = pd.concat([lat_summary, lon_summary, rad_summary])\n",
    "    combined.to_csv(out_dir / \"resumo_geral.csv\")\n",
    "\n",
    "# =========================\n",
    "# Execu√ß√£o por per√≠odo\n",
    "# =========================\n",
    "for periodo in [\"manha\", \"tarde\"]:\n",
    "    subset = df[df[\"periodo\"] == periodo]\n",
    "    if len(subset) > 0:\n",
    "        analisar_periodo(subset, periodo)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Nenhum dado dispon√≠vel para {periodo}\")\n",
    "\n",
    "print(\"\\nüíæ Resultados salvos em:\", BASE_OUTPUT.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5d13f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dataset...\n",
      "‚úÖ Registros v√°lidos: 419,878\n",
      "\n",
      "=== COMPARATIVO: diferencalatitudeMetros ===\n",
      "metric     manh√£     tarde  diferen√ßa  diferen√ßa_%\n",
      "  mean   0.55963   4.60887    4.04924       723.56\n",
      "median   0.83000   4.70000    3.87000       466.27\n",
      "   std   4.09971   5.82967    1.72997        42.20\n",
      "   var  16.80760  33.98508   17.17749       102.20\n",
      "    Q1  -0.84000   2.92000    3.76000       447.62\n",
      "    Q2   0.83000   4.70000    3.87000       466.27\n",
      "    Q3   1.57000   6.09000    4.52000       287.90\n",
      "   IQR   2.41000   3.17000    0.76000        31.54\n",
      "   min -87.88000 -85.46000    2.42000         2.75\n",
      "   max  74.74000  78.20000    3.46000         4.63\n",
      " range 162.62000 163.66000    1.04000         0.64\n",
      "   mad   1.78348   2.53626    0.75278        42.21\n",
      "\n",
      "=== COMPARATIVO: diferencalongitudeMetros ===\n",
      "metric      manh√£      tarde  diferen√ßa  diferen√ßa_%\n",
      "  mean    0.59107   -0.40736   -0.99843      -168.92\n",
      "median    0.39000   -0.62000   -1.01000      -258.97\n",
      "   std    5.19197    7.97224    2.78027        53.55\n",
      "   var   26.95658   63.55668   36.60010       135.77\n",
      "    Q1   -0.66000   -1.84000   -1.18000      -178.79\n",
      "    Q2    0.39000   -0.62000   -1.01000      -258.97\n",
      "    Q3    1.69000    0.76000   -0.93000       -55.03\n",
      "   IQR    2.35000    2.60000    0.25000        10.64\n",
      "   min -124.37000 -111.42000   12.95000        10.41\n",
      "   max  134.16000  130.45000   -3.71000        -2.77\n",
      " range  258.53000  241.87000  -16.66000        -6.44\n",
      "   mad    1.94578    2.48376    0.53798        27.65\n",
      "\n",
      "=== COMPARATIVO: erro_radial_m ===\n",
      "metric     manh√£     tarde  diferen√ßa  diferen√ßa_%\n",
      "  mean   2.98110   6.31924    3.33814       111.98\n",
      "median   2.15081   5.17186    3.02104       140.46\n",
      "   std   5.96152   8.88912    2.92760        49.11\n",
      "   var  35.53973  79.01654   43.47680       122.33\n",
      "    Q1   1.39129   3.68470    2.29340       164.84\n",
      "    Q2   2.15081   5.17186    3.02104       140.46\n",
      "    Q3   2.98605   6.30147    3.31542       111.03\n",
      "   IQR   1.59476   2.61677    1.02201        64.09\n",
      "   min   0.31321   0.25000   -0.06321       -20.18\n",
      "   max 152.59160 149.88368   -2.70791        -1.77\n",
      " range 152.27839 149.63368   -2.64470        -1.74\n",
      "   mad   1.81558   3.10940    1.29382        71.26\n",
      "\n",
      "üíæ Arquivos comparativos e figuras salvos em: D:\\[TCC]\\CODE\\parte1_resultados_comparativo\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Comparativo estat√≠stico entre per√≠odos (manh√£ vs tarde)\n",
    "Base: Dataset_Vetor.json\n",
    "Corte: timestamp < 0.5 (manh√£) / >= 0.5 (tarde)\n",
    "Foco: compara√ß√µes de quartis, dispers√£o e m√©tricas de erro GNSS\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "# ===============================\n",
    "# Configura√ß√µes\n",
    "# ===============================\n",
    "JSON_PATH = \"Dataset_Vetor.json\"\n",
    "OUTPUT_DIR = Path(\"./parte1_resultados_comparativo\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "lat_col = \"diferencalatitudeMetros\"\n",
    "lon_col = \"diferencalongitudeMetros\"\n",
    "\n",
    "# ===============================\n",
    "# Carregamento e limpeza\n",
    "# ===============================\n",
    "print(\"Carregando dataset...\")\n",
    "with open(JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "required = [lat_col, lon_col, \"timestamp\"]\n",
    "missing = [c for c in required if c not in df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Faltando colunas obrigat√≥rias: {missing}\")\n",
    "\n",
    "for c in required:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=required)\n",
    "print(f\"‚úÖ Registros v√°lidos: {len(df):,}\")\n",
    "\n",
    "df[\"periodo\"] = np.where(df[\"timestamp\"] < 0.5, \"manh√£\", \"tarde\")\n",
    "df[\"erro_radial_m\"] = np.sqrt(df[lat_col]**2 + df[lon_col]**2)\n",
    "\n",
    "# ===============================\n",
    "# Fun√ß√µes auxiliares\n",
    "# ===============================\n",
    "def resumo_quartil(series):\n",
    "    q = series.quantile([0.25, 0.5, 0.75])\n",
    "    iqr = q.loc[0.75] - q.loc[0.25]\n",
    "    return {\n",
    "        \"mean\": series.mean(),\n",
    "        \"median\": q.loc[0.5],\n",
    "        \"std\": series.std(ddof=1),\n",
    "        \"var\": series.var(ddof=1),\n",
    "        \"Q1\": q.loc[0.25],\n",
    "        \"Q2\": q.loc[0.5],\n",
    "        \"Q3\": q.loc[0.75],\n",
    "        \"IQR\": iqr,\n",
    "        \"min\": series.min(),\n",
    "        \"max\": series.max(),\n",
    "        \"range\": series.max() - series.min(),\n",
    "        \"mad\": (series - series.mean()).abs().mean(),\n",
    "    }\n",
    "\n",
    "def comparar_periodos(df, coluna):\n",
    "    manha = df[df[\"periodo\"] == \"manh√£\"][coluna]\n",
    "    tarde = df[df[\"periodo\"] == \"tarde\"][coluna]\n",
    "\n",
    "    stats = {\n",
    "        \"metric\": [],\n",
    "        \"manh√£\": [],\n",
    "        \"tarde\": [],\n",
    "        \"diferen√ßa\": [],\n",
    "        \"diferen√ßa_%\": [],\n",
    "    }\n",
    "\n",
    "    m = resumo_quartil(manha)\n",
    "    t = resumo_quartil(tarde)\n",
    "\n",
    "    for key in m.keys():\n",
    "        diff = t[key] - m[key]\n",
    "        perc = (diff / abs(m[key]) * 100) if m[key] != 0 else np.nan\n",
    "        stats[\"metric\"].append(key)\n",
    "        stats[\"manh√£\"].append(round(m[key], 5))\n",
    "        stats[\"tarde\"].append(round(t[key], 5))\n",
    "        stats[\"diferen√ßa\"].append(round(diff, 5))\n",
    "        stats[\"diferen√ßa_%\"].append(round(perc, 2))\n",
    "\n",
    "    df_comp = pd.DataFrame(stats)\n",
    "    return df_comp\n",
    "\n",
    "# ===============================\n",
    "# Compara√ß√£o LATITUDE / LONGITUDE / RADIAL\n",
    "# ===============================\n",
    "comparativos = {}\n",
    "for var in [lat_col, lon_col, \"erro_radial_m\"]:\n",
    "    comp = comparar_periodos(df, var)\n",
    "    comparativos[var] = comp\n",
    "    comp.to_csv(OUTPUT_DIR / f\"comparativo_{var}.csv\", index=False)\n",
    "    print(f\"\\n=== COMPARATIVO: {var} ===\")\n",
    "    print(comp.to_string(index=False))\n",
    "\n",
    "# ===============================\n",
    "# Visualiza√ß√µes (para o TCC)\n",
    "# ===============================\n",
    "sns.set_palette(\"muted\")\n",
    "\n",
    "def gerar_boxplots(col, nome):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(x=\"periodo\", y=col, data=df, width=0.5)\n",
    "    plt.title(f\"Boxplot do erro em {nome} (m) ‚Äì manh√£ vs tarde\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"Erro (m)\")\n",
    "    plt.savefig(OUTPUT_DIR / f\"boxplot_{nome}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def gerar_violinplots(col, nome):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.violinplot(x=\"periodo\", y=col, data=df, inner=\"quartile\")\n",
    "    plt.title(f\"Distribui√ß√£o (Violin) ‚Äì {nome} GNSS\")\n",
    "    plt.ylabel(\"Erro (m)\")\n",
    "    plt.savefig(OUTPUT_DIR / f\"violin_{nome}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def gerar_barras(col, nome):\n",
    "    agg = df.groupby(\"periodo\")[col].agg([\"mean\", \"std\"])\n",
    "    agg[\"sem\"] = agg[\"std\"] / np.sqrt(df.groupby(\"periodo\")[col].count())\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.bar(agg.index, agg[\"mean\"], yerr=agg[\"sem\"], capsize=6, color=[\"#1f77b4\", \"#ff7f0e\"])\n",
    "    plt.title(f\"M√©dia ¬± erro padr√£o ‚Äì {nome} GNSS\")\n",
    "    plt.ylabel(\"Erro m√©dio (m)\")\n",
    "    plt.savefig(OUTPUT_DIR / f\"barras_{nome}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "for col, nome in zip([lat_col, lon_col, \"erro_radial_m\"], [\"Latitude\", \"Longitude\", \"Erro Radial\"]):\n",
    "    gerar_boxplots(col, nome)\n",
    "    gerar_violinplots(col, nome)\n",
    "    gerar_barras(col, nome)\n",
    "\n",
    "print(\"\\nüíæ Arquivos comparativos e figuras salvos em:\", OUTPUT_DIR.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
